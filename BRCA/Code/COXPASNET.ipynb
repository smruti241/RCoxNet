{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5ff96b45",
      "metadata": {
        "id": "5ff96b45"
      },
      "outputs": [],
      "source": [
        "path = \"D:\\Cox-nnet\\pathway_mask_tcga_brca.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fe37a65f",
      "metadata": {
        "id": "fe37a65f"
      },
      "outputs": [],
      "source": [
        "##%%writefile DataLoader.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def sort_data(path):\n",
        "\t''' sort the genomic and clinical data w.r.t. survival time (OS_MONTHS) in descending order\n",
        "\tInput:\n",
        "\t\tpath: path to input dataset (which is expected to be a csv file).\n",
        "\tOutput:\n",
        "\t\tx: sorted genomic inputs.\n",
        "\t\tytime: sorted survival time (OS_MONTHS) corresponding to 'x'.\n",
        "\t\tyevent: sorted censoring status (OS_EVENT) corresponding to 'x', where 1 --> deceased; 0 --> censored.\n",
        "\t\tage: sorted age corresponding to 'x'.\n",
        "\t'''\n",
        "\n",
        "\tdata = pd.read_csv(path)\n",
        "\n",
        "\tdata.sort_values(\"OS_MONTHS\", ascending = False, inplace = True)\n",
        "\n",
        "\tx = data.drop([\"SAMPLE_ID\", \"OS_MONTHS\", \"OS_EVENT\", \"AGE\"], axis = 1).values #remove age\n",
        "\tytime = data.loc[:, [\"OS_MONTHS\"]].values\n",
        "\tyevent = data.loc[:, [\"OS_EVENT\"]].values\n",
        "\tage = data.loc[:, [\"AGE\"]].values   #remove age\n",
        "\n",
        "\treturn(x, ytime, yevent, age)  #remove age\n",
        "\n",
        "\n",
        "def load_data(path, dtype):\n",
        "\t'''Load the sorted data, and then covert it to a Pytorch tensor.\n",
        "\tInput:\n",
        "\t\tpath: path to input dataset (which is expected to be a csv file).\n",
        "\t\tdtype: define the data type of tensor (i.e. dtype=torch.FloatTensor)\n",
        "\tOutput:\n",
        "\t\tX: a Pytorch tensor of 'x' from sort_data().\n",
        "\t\tYTIME: a Pytorch tensor of 'ytime' from sort_data().\n",
        "\t\tYEVENT: a Pytorch tensor of 'yevent' from sort_data().\n",
        "\t\tAGE: a Pytorch tensor of 'age' from sort_data().\n",
        "\t'''\n",
        "\tx, ytime, yevent, age = sort_data(path)  #remove age\n",
        "\t###\n",
        "\n",
        "\tX = torch.from_numpy(x).type(dtype)\n",
        "\tYTIME = torch.from_numpy(ytime).type(dtype)\n",
        "\tYEVENT = torch.from_numpy(yevent).type(dtype)\n",
        "\tAGE = torch.from_numpy(age).type(dtype)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tX = X.cuda()\n",
        "\t\tYTIME = YTIME.cuda()\n",
        "\t\tYEVENT = YEVENT.cuda()\n",
        "\t\tAGE = AGE.cuda() #remove age\n",
        "\t###\n",
        "\treturn(X, YTIME, YEVENT, AGE)   #remove age\n",
        "\n",
        "\n",
        "def load_pathway(path, dtype):\n",
        "\t'''Load a bi-adjacency matrix of pathways, and then covert it to a Pytorch tensor.\n",
        "\tInput:\n",
        "\t\tpath: path to input dataset (which is expected to be a csv file).\n",
        "\t\tdtype: define the data type of tensor (i.e. dtype=torch.FloatTensor)\n",
        "\tOutput:\n",
        "\t\tPATHWAY_MASK: a Pytorch tensor of the bi-adjacency matrix of pathways.\n",
        "\t'''\n",
        "\tpathway_mask = pd.read_csv(path, index_col = 0).values\n",
        "\n",
        "\tPATHWAY_MASK = torch.from_numpy(pathway_mask).type(dtype)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tPATHWAY_MASK = PATHWAY_MASK.cuda()\n",
        "\t###\n",
        "\treturn(PATHWAY_MASK)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "61fdcf41",
      "metadata": {
        "id": "61fdcf41"
      },
      "outputs": [],
      "source": [
        "# pwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3b98a639",
      "metadata": {
        "id": "3b98a639"
      },
      "outputs": [],
      "source": [
        "# PATHWAY_MASK=load_pathway(path,dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "91444011",
      "metadata": {
        "id": "91444011"
      },
      "outputs": [],
      "source": [
        "# PATHWAY_MASK[500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8fa655ca",
      "metadata": {
        "id": "8fa655ca"
      },
      "outputs": [],
      "source": [
        "# x_train, ytime_train, yevent_train, age_train = load_data(\"train_tcga_ov.csv\", dtype)\n",
        "# x_valid, ytime_valid, yevent_valid, age_valid = load_data(\"validation_data_tcga_ov.csv\", dtype)\n",
        "# x_test, ytime_test, yevent_test, age_test = load_data(\"test_final_tcga_Brca.csv\", dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2fbecc25",
      "metadata": {
        "id": "2fbecc25"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "52c39488",
      "metadata": {
        "id": "52c39488"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Cox_PASNet(nn.Module):\n",
        "# \tdef __init__(self, In_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, Pathway_Mask):\n",
        "\tdef __init__(self, In_Nodes, Hidden_Nodes, Out_Nodes):\n",
        "\t\tsuper(Cox_PASNet, self).__init__()\n",
        "\t\tself.tanh = nn.Tanh()\n",
        "# \t\tself.pathway_mask = Pathway_Mask\n",
        "\t\t###gene layer --> pathway layer\n",
        "# \t\tself.sc1 = nn.Linear(In_Nodes, Pathway_Nodes)\n",
        "\t\tself.sc1 = nn.Linear(In_Nodes,860)\n",
        "\t\t###pathway layer --> hidden layer\n",
        "# \t\tself.sc2 = nn.Linear(Pathway_Nodes, Hidden_Nodes)\n",
        "\t\tself.sc2 = nn.Linear(860,Hidden_Nodes)\n",
        "\t\t###hidden layer --> hidden layer 2\n",
        "\t\tself.sc3 = nn.Linear(Hidden_Nodes, Out_Nodes, bias=False)\n",
        "\t\t###hidden layer 2 + age --> Cox layer\n",
        "\t\tself.sc4 = nn.Linear(Out_Nodes+1, 1, bias = False) # replace nn.Linear(Out_Nodes, 1, bias = False)\n",
        "\t\tself.sc4.weight.data.uniform_(-0.001, 0.001)\n",
        "\t\t###randomly select a small sub-network\n",
        "# \t\tself.do_m1 = torch.ones(Pathway_Nodes)\n",
        "\t\tself.do_m2 = torch.ones(Hidden_Nodes)\n",
        "\t\t###if gpu is being used\n",
        "\t\tif torch.cuda.is_available():\n",
        "\t\t\tself.do_m1 = self.do_m1.cuda()\n",
        "\t\t\tself.do_m2 = self.do_m2.cuda()\n",
        "\t\t###\n",
        "\n",
        "\tdef forward(self, x_1, x_2):\n",
        "\t\t###force the connections between gene layer and pathway layer w.r.t. 'pathway_mask'\n",
        "# \t\tself.sc1.weight.data = self.sc1.weight.data.mul(self.pathway_mask)\n",
        "\t\tx_1 = self.tanh(self.sc1(x_1))\n",
        "\t\tif self.training == True: ###construct a small sub-network for training only\n",
        "\t\t\tx_1 = x_1.mul(self.do_m1)\n",
        "\t\tx_1 = self.tanh(self.sc2(x_1))\n",
        "\t\tif self.training == True: ###construct a small sub-network for training only\n",
        "\t\t\tx_1 = x_1.mul(self.do_m2)\n",
        "\t\tx_1 = self.tanh(self.sc3(x_1))\n",
        "\t\t###combine age with hidden layer 2\n",
        "\t\tx_cat = torch.cat((x_1, x_2), 1) # will have to check variable x_2 and , 1\n",
        "\t\tlin_pred = self.sc4(x_cat)\n",
        "\n",
        "\t\treturn lin_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3a65e9a6",
      "metadata": {
        "id": "3a65e9a6"
      },
      "outputs": [],
      "source": [
        "#%%writefile SubNetwork_SparseCoding.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def dropout_mask(n_node, drop_p):\n",
        "\t'''Construct a binary matrix to randomly drop nodes in a layer.\n",
        "\tInput:\n",
        "\t\tn_node: number of nodes in the layer.\n",
        "\t\tdrop_p: the probability that a node is to be dropped.\n",
        "\tOutput:\n",
        "\t\tmask: a binary matrix, where 1 --> keep the node; 0 --> drop the node.\n",
        "\t'''\n",
        "\tkeep_p = 1.0 - drop_p\n",
        "\tmask = torch.Tensor(np.random.binomial(1, keep_p, size=n_node))\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tmask = mask.cuda()\n",
        "\t###\n",
        "\treturn mask\n",
        "\n",
        "def s_mask(sparse_level, param_matrix, nonzero_param_1D, dtype):\n",
        "\t'''Construct a binary matrix w.r.t. a sparsity level of weights between two consecutive layers\n",
        "\tInput:\n",
        "\t\tsparse_level: a percentage value in [0, 100) represents the proportion of weights in a sub-network to be dropped.\n",
        "\t\tparam_matrix: a weight matrix for entrie network.\n",
        "\t\tnonzero_param_1D: 1D of non-zero 'param_matrix' (which is the weights selected from a sub-network).\n",
        "\t\tdtype: define the data type of tensor (i.e. dtype=torch.FloatTensor).\n",
        "\tOutput:\n",
        "\t\tparam_mask: a binary matrix, where 1 --> keep the node; 0 --> drop the node.\n",
        "\t'''\n",
        "\t###take the absolute values of param_1D\n",
        "\tnon_neg_param_1D = torch.abs(nonzero_param_1D)\n",
        "\t###obtain the number of params\n",
        "\tnum_param = nonzero_param_1D.size(0)\n",
        "\t###obtain the kth number based on sparse_level\n",
        "\ttop_k = math.ceil(num_param*(100-sparse_level)*0.01)\n",
        "\t###obtain the k largest params\n",
        "\tsorted_non_neg_param_1D, indices = torch.topk(non_neg_param_1D, top_k)\n",
        "\tparam_mask = torch.abs(param_matrix) > sorted_non_neg_param_1D.min()\n",
        "\tparam_mask = param_mask.type(dtype)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tparam_mask = param_mask.cuda()\n",
        "\t###\n",
        "\treturn param_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "47e034ee",
      "metadata": {
        "id": "47e034ee"
      },
      "outputs": [],
      "source": [
        "#writefile Survival_CostFunc_CIndex.py\n",
        "import torch\n",
        "\n",
        "def R_set(x):\n",
        "\t'''Create an indicator matrix of risk sets, where T_j >= T_i.\n",
        "\tNote that the input data have been sorted in descending order.\n",
        "\tInput:\n",
        "\t\tx: a PyTorch tensor that the number of rows is equal to the number of samples.\n",
        "\tOutput:\n",
        "\t\tindicator_matrix: an indicator matrix (which is a lower traiangular portions of matrix).\n",
        "\t'''\n",
        "\tn_sample = x.size(0)\n",
        "\tmatrix_ones = torch.ones(n_sample, n_sample)\n",
        "\tindicator_matrix = torch.tril(matrix_ones)\n",
        "\n",
        "\treturn(indicator_matrix)\n",
        "\n",
        "def neg_par_log_likelihood(pred, ytime, yevent):\n",
        "\t'''Calculate the average Cox negative partial log-likelihood.\n",
        "\tNote that this function requires the input data have been sorted in descending order.\n",
        "\tInput:\n",
        "\t\tpred: linear predictors from trained model.\n",
        "\t\tytime: true survival time from load_data().\n",
        "\t\tyevent: true censoring status from load_data().\n",
        "\tOutput:\n",
        "\t\tcost: the cost that is to be minimized.\n",
        "\t'''\n",
        "\tn_observed = yevent.sum(0)\n",
        "\tytime_indicator = R_set(ytime)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tytime_indicator = ytime_indicator.cuda()\n",
        "\t###\n",
        "\trisk_set_sum = ytime_indicator.mm(torch.exp(pred))\n",
        "\tdiff = pred - torch.log(risk_set_sum)\n",
        "\tsum_diff_in_observed = torch.transpose(diff, 0, 1).mm(yevent)\n",
        "\tcost = (- (sum_diff_in_observed / n_observed)).reshape((-1,))\n",
        "\n",
        "\treturn(cost)\n",
        "\n",
        "\n",
        "def c_index(pred, ytime, yevent):\n",
        "\t'''Calculate concordance index to evaluate models.\n",
        "\tInput:\n",
        "\t\tpred: linear predictors from trained model.\n",
        "\t\tytime: true survival time from load_data().\n",
        "\t\tyevent: true censoring status from load_data().\n",
        "\tOutput:\n",
        "\t\tconcordance_index: c-index (between 0 and 1).\n",
        "\t'''\n",
        "\tn_sample = len(ytime)\n",
        "\tytime_indicator = R_set(ytime)\n",
        "\tytime_matrix = ytime_indicator - torch.diag(torch.diag(ytime_indicator))\n",
        "\t###T_i is uncensored\n",
        "\tcensor_idx = (yevent == 0).nonzero()\n",
        "\tzeros = torch.zeros(n_sample)\n",
        "\tytime_matrix[censor_idx, :] = zeros\n",
        "\t###1 if pred_i < pred_j; 0.5 if pred_i = pred_j\n",
        "\tpred_matrix = torch.zeros_like(ytime_matrix)\n",
        "\tfor j in range(n_sample):\n",
        "\t\tfor i in range(n_sample):\n",
        "\t\t\tif pred[i] < pred[j]:\n",
        "\t\t\t\tpred_matrix[j, i]  = 1\n",
        "\t\t\telif pred[i] == pred[j]:\n",
        "\t\t\t\tpred_matrix[j, i] = 0.5\n",
        "\n",
        "\tconcord_matrix = pred_matrix.mul(ytime_matrix)\n",
        "\t###numerator\n",
        "\tconcord = torch.sum(concord_matrix)\n",
        "\t###denominator\n",
        "\tepsilon = torch.sum(ytime_matrix)\n",
        "\t###c-index = numerator/denominator\n",
        "\tconcordance_index = torch.div(concord, epsilon)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tconcordance_index = concordance_index.cuda()\n",
        "\t###\n",
        "\treturn(concordance_index)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "856e96be",
      "metadata": {
        "id": "856e96be"
      },
      "outputs": [],
      "source": [
        "# from Model import Cox_PASNet\n",
        "# from SubNetwork_SparseCoding import dropout_mask, s_mask\n",
        "# from Survival_CostFunc_CIndex import R_set, neg_par_log_likelihood, c_index\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "from scipy.interpolate import interp1d\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dtype = torch.FloatTensor\n",
        "# Dropout_Rate = [0.7,0.5]\n",
        "\n",
        "def trainCoxPASNet(train_x, train_age, train_ytime, train_yevent,eval_x, eval_age, eval_ytime, eval_yevent,In_Nodes, Hidden_Nodes, Out_Nodes,Learning_Rate, L2, Num_Epochs, Dropout_Rate):\n",
        "\n",
        "\n",
        "\tnet = Cox_PASNet(In_Nodes, Hidden_Nodes, Out_Nodes)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tnet.cuda()\n",
        "\t###\n",
        "\t###optimizer\n",
        "\topt = optim.Adam(net.parameters(), lr=Learning_Rate, weight_decay = L2)\n",
        "\n",
        "\tfor epoch in range(Num_Epochs+1):\n",
        "\t\tnet.train()\n",
        "\t\topt.zero_grad() ###reset gradients to zeros\n",
        "\t\t###Randomize dropout masks\n",
        "# \t\tnet.do_m1 = dropout_mask(Dropout_Rate[0])\n",
        "# \t\tnet.do_m2 = dropout_mask(Hidden_Nodes, Dropout_Rate[1])\n",
        "\t\tnet.do_m1 = dropout_mask(860, Dropout_Rate[0])\n",
        "\t\tnet.do_m2 = dropout_mask(150, Dropout_Rate[1])\n",
        "# \t\tprint(\"*******\",net.do_m1)\n",
        "\n",
        "\n",
        "\t\tpred = net(train_x, train_age) ###Forward\n",
        "\t\tloss = neg_par_log_likelihood(pred, train_ytime, train_yevent) ###calculate loss\n",
        "\t\tloss.backward() ###calculate gradients\n",
        "\t\topt.step() ###update weights and biases\n",
        "\n",
        "# \t\tnet.sc1.weight.data = net.sc1.weight.data.mul(net.pathway_mask) ###force the connections between gene layer and pathway layer\n",
        "\n",
        "\t\t###obtain the small sub-network's connections\n",
        "\t\tdo_m1_grad = copy.deepcopy(net.sc2.weight._grad.data)\n",
        "\t\tdo_m2_grad = copy.deepcopy(net.sc3.weight._grad.data)\n",
        "\t\tdo_m1_grad_mask = torch.where(do_m1_grad == 0, do_m1_grad, torch.ones_like(do_m1_grad))\n",
        "\t\tdo_m2_grad_mask = torch.where(do_m2_grad == 0, do_m2_grad, torch.ones_like(do_m2_grad))\n",
        "\t\t###copy the weights\n",
        "\t\tnet_sc2_weight = copy.deepcopy(net.sc2.weight.data)\n",
        "\t\tnet_sc3_weight = copy.deepcopy(net.sc3.weight.data)\n",
        "\n",
        "\t\t###serializing net\n",
        "\t\tnet_state_dict = net.state_dict()\n",
        "\n",
        "\t\t###Sparse Coding\n",
        "\t\t###make a copy for net, and then optimize sparsity level via copied net\n",
        "\t\tcopy_net = copy.deepcopy(net)\n",
        "\t\tcopy_state_dict = copy_net.state_dict()\n",
        "\t\tfor name, param in copy_state_dict.items():\n",
        "\t\t\t###omit the param if it is not a weight matrix\n",
        "\t\t\tif not \"weight\" in name:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t###omit gene layer\n",
        "\t\t\tif \"sc1\" in name:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t###stop sparse coding\n",
        "\t\t\tif \"sc4\" in name:\n",
        "\t\t\t\tbreak\n",
        "\t\t\t###sparse coding between the current two consecutive layers is in the trained small sub-network\n",
        "\t\t\tif \"sc2\" in name:\n",
        "\t\t\t\tactive_param = net_sc2_weight.mul(do_m1_grad_mask)\n",
        "\t\t\tif \"sc3\" in name:\n",
        "\t\t\t\tactive_param = net_sc3_weight.mul(do_m2_grad_mask)\n",
        "\t\t\tnonzero_param_1d = active_param[active_param != 0]\n",
        "\t\t\tif nonzero_param_1d.size(0) == 0: ###stop sparse coding between the current two consecutive layers if there are no valid weights\n",
        "\t\t\t\tbreak\n",
        "\t\t\tcopy_param_1d = copy.deepcopy(nonzero_param_1d)\n",
        "\t\t\t###set up potential sparsity level in [0, 100)\n",
        "\t\t\tS_set =  torch.arange(100, -1, -1)[1:]\n",
        "\t\t\tcopy_param = copy.deepcopy(active_param)\n",
        "\t\t\tS_loss = []\n",
        "\t\t\tfor S in S_set:\n",
        "\t\t\t\tparam_mask = s_mask(sparse_level = S.item(), param_matrix = copy_param, nonzero_param_1D = copy_param_1d, dtype = dtype)\n",
        "\t\t\t\ttransformed_param = copy_param.mul(param_mask)\n",
        "\t\t\t\tcopy_state_dict[name].copy_(transformed_param)\n",
        "\t\t\t\tcopy_net.train()\n",
        "\t\t\t\ty_tmp = copy_net(train_x, train_age)\n",
        "\t\t\t\tloss_tmp = neg_par_log_likelihood(y_tmp, train_ytime, train_yevent)\n",
        "\t\t\t\tS_loss.append(loss_tmp)\n",
        "\t\t\t#print(type(S_loss))\n",
        "\t\t\t#print(type(S_set))\n",
        "\t\t\tS_loss = torch.tensor(S_loss)\n",
        "\t\t\tS_loss = S_loss.detach().numpy()\n",
        "\t\t\tS_set = S_set.detach().numpy()\n",
        "\t\t\t#print(type(S_loss))\n",
        "\t\t\t#print(type(S_set))\n",
        "\t\t\t###apply cubic interpolation\n",
        "\t\t\tinterp_S_loss = interp1d(S_set, S_loss, kind='cubic')\n",
        "\t\t\tinterp_S_set = torch.linspace(min(S_set), max(S_set), steps=100)\n",
        "\t\t\tinterp_loss = interp_S_loss(interp_S_set)\n",
        "\t\t\toptimal_S = interp_S_set[np.argmin(interp_loss)]\n",
        "\t\t\toptimal_param_mask = s_mask(sparse_level = optimal_S.item(), param_matrix = copy_param, nonzero_param_1D = copy_param_1d, dtype = dtype)\n",
        "\t\t\tif \"sc2\" in name:\n",
        "\t\t\t\tfinal_optimal_param_mask = torch.where(do_m1_grad_mask == 0, torch.ones_like(do_m1_grad_mask), optimal_param_mask)\n",
        "\t\t\t\toptimal_transformed_param = net_sc2_weight.mul(final_optimal_param_mask)\n",
        "\t\t\tif \"sc3\" in name:\n",
        "\t\t\t\tfinal_optimal_param_mask = torch.where(do_m2_grad_mask == 0, torch.ones_like(do_m2_grad_mask), optimal_param_mask)\n",
        "\t\t\t\toptimal_transformed_param = net_sc3_weight.mul(final_optimal_param_mask)\n",
        "\t\t\t###update weights in copied net\n",
        "\t\t\tcopy_state_dict[name].copy_(optimal_transformed_param)\n",
        "\t\t\t###update weights in net\n",
        "\t\t\tnet_state_dict[name].copy_(optimal_transformed_param)\n",
        "\n",
        "\t\tif epoch % 200 == 0:\n",
        "\t\t\tnet.train()\n",
        "\t\t\ttrain_pred = net(train_x, train_age)\n",
        "\t\t\ttrain_loss = neg_par_log_likelihood(train_pred, train_ytime, train_yevent).view(1,)\n",
        "\n",
        "\t\t\tnet.eval()\n",
        "\t\t\teval_pred = net(eval_x, eval_age)\n",
        "\t\t\teval_loss = neg_par_log_likelihood(eval_pred, eval_ytime, eval_yevent).view(1,)\n",
        "\n",
        "\t\t\ttrain_cindex = c_index(train_pred, train_ytime, train_yevent)\n",
        "\t\t\teval_cindex = c_index(eval_pred, eval_ytime, eval_yevent)\n",
        "\t\t\tprint(\"Loss in Train: \", train_loss)\n",
        "\n",
        "\treturn (train_loss, eval_loss, train_cindex, eval_cindex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "da667d93",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da667d93",
        "outputId": "f7d92db1-6105-4028-d7b8-f8c4558835f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss in Train:  tensor([5.0042], grad_fn=<ViewBackward0>)\n",
            "L2:  0.1 LR:  0.03 Loss in Validation:  tensor([3.9124], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0460], grad_fn=<ViewBackward0>)\n",
            "L2:  0.1 LR:  0.01 Loss in Validation:  tensor([3.8228], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0856], grad_fn=<ViewBackward0>)\n",
            "L2:  0.1 LR:  0.001 Loss in Validation:  tensor([3.7989], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0866], grad_fn=<ViewBackward0>)\n",
            "L2:  0.1 LR:  0.00075 Loss in Validation:  tensor([3.7985], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0041], grad_fn=<ViewBackward0>)\n",
            "L2:  0.01 LR:  0.03 Loss in Validation:  tensor([3.9132], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0502], grad_fn=<ViewBackward0>)\n",
            "L2:  0.01 LR:  0.01 Loss in Validation:  tensor([3.8193], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0884], grad_fn=<ViewBackward0>)\n",
            "L2:  0.01 LR:  0.001 Loss in Validation:  tensor([3.7978], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0955], grad_fn=<ViewBackward0>)\n",
            "L2:  0.01 LR:  0.00075 Loss in Validation:  tensor([3.7952], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0038], grad_fn=<ViewBackward0>)\n",
            "L2:  0.005 LR:  0.03 Loss in Validation:  tensor([3.9165], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0482], grad_fn=<ViewBackward0>)\n",
            "L2:  0.005 LR:  0.01 Loss in Validation:  tensor([3.8209], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0853], grad_fn=<ViewBackward0>)\n",
            "L2:  0.005 LR:  0.001 Loss in Validation:  tensor([3.7991], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0913], grad_fn=<ViewBackward0>)\n",
            "L2:  0.005 LR:  0.00075 Loss in Validation:  tensor([3.7967], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0045], grad_fn=<ViewBackward0>)\n",
            "L2:  0.001 LR:  0.03 Loss in Validation:  tensor([3.9090], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0480], grad_fn=<ViewBackward0>)\n",
            "L2:  0.001 LR:  0.01 Loss in Validation:  tensor([3.8211], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0918], grad_fn=<ViewBackward0>)\n",
            "L2:  0.001 LR:  0.001 Loss in Validation:  tensor([3.7965], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0946], grad_fn=<ViewBackward0>)\n",
            "L2:  0.001 LR:  0.00075 Loss in Validation:  tensor([3.7955], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0899], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0033], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0033], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0033], grad_fn=<ViewBackward0>)\n",
            "Loss in Train:  tensor([5.0033], grad_fn=<ViewBackward0>)\n",
            "Optimal L2:  0.01 Optimal LR:  0.00075\n",
            "C-index in Test:  tensor(0.6773)\n"
          ]
        }
      ],
      "source": [
        "#from DataLoader import load_data, load_pathway\n",
        "#from Train import trainCoxPASNet\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "''' Net Settings'''\n",
        "In_Nodes = 270 ###number of genes\n",
        "# Pathway_Nodes = 860 ###number of pathways\n",
        "Hidden_Nodes = 150 ###number of hidden nodes\n",
        "Out_Nodes = 30 ###number of hidden nodes in the last hidden layer\n",
        "''' Initialize '''\n",
        "Initial_Learning_Rate = [0.03, 0.01, 0.001, 0.00075]\n",
        "# L2_Lambda = [0.1]\n",
        "num_epochs = 100 ###for grid search\n",
        "Num_EPOCHS =900 ###for training\n",
        "Dropout_Rate = [0.7, 0.5]\n",
        "###sub-network setup\n",
        "L2_Lambda = [0.1, 0.01, 0.005, 0.001]\n",
        "''' load data and pathway '''\n",
        "# pathway_mask = load_pathway(\"pathway_mask_tcga_ov.csv\", dtype)\n",
        "\n",
        "# x_train, ytime_train, yevent_train, age_train = load_data(\"train_tcga_ov.csv\", dtype)\n",
        "# x_valid, ytime_valid, yevent_valid, age_valid = load_data(\"validation_data_tcga_ov.csv\", dtype)\n",
        "# x_test, ytime_test, yevent_test, age_test = load_data(\"test_final_tcga_ov.csv\", dtype)\n",
        "x_train, ytime_train, yevent_train, age_train = load_data(\"/content/train_tcga_Brca.csv\", dtype)\n",
        "x_valid, ytime_valid, yevent_valid, age_valid = load_data(\"/content/validation_data_tcga_Brca.csv\", dtype)\n",
        "x_test, ytime_test, yevent_test, age_test = load_data(\"/content/test_final_tcga_Brca.csv\", dtype)\n",
        "\n",
        "opt_l2_loss = 0\n",
        "opt_lr_loss = 0\n",
        "opt_loss = torch.Tensor([float(\"Inf\")])\n",
        "###if gpu is being used\n",
        "if torch.cuda.is_available():\n",
        "\topt_loss = opt_loss.cuda()\n",
        "###\n",
        "opt_c_index_va = 0\n",
        "opt_c_index_tr = 0\n",
        "###grid search the optimal hyperparameters using train and validation data\n",
        "for l2 in L2_Lambda:\n",
        "\tfor lr in Initial_Learning_Rate:\n",
        "\t\tloss_train, loss_valid, c_index_tr, c_index_va = trainCoxPASNet(x_train, age_train, ytime_train, yevent_train,x_valid, age_valid, ytime_valid, yevent_valid,In_Nodes, Hidden_Nodes, Out_Nodes,lr, l2, num_epochs, Dropout_Rate)\n",
        "\t\tif loss_valid < opt_loss:\n",
        "\t\t\topt_l2_loss = l2\n",
        "\t\t\topt_lr_loss = lr\n",
        "\t\t\topt_loss = loss_valid\n",
        "\t\t\topt_c_index_tr = c_index_tr\n",
        "\t\t\topt_c_index_va = c_index_va\n",
        "\t\tprint (\"L2: \", l2, \"LR: \", lr, \"Loss in Validation: \", loss_valid)\n",
        "\n",
        "###train Cox-PASNet with optimal hyperparameters using train data, and then evaluate the trained model with test data\n",
        "###Note that test data are only used to evaluate the trained Cox-PASNet\n",
        "loss_train, loss_test, c_index_tr, c_index_te = trainCoxPASNet(x_train, age_train, ytime_train, yevent_train, \\\n",
        "\t\t\t\t\t\t\tx_test, age_test, ytime_test, yevent_test, \\\n",
        "\t\t\t\t\t\t\tIn_Nodes, Hidden_Nodes, Out_Nodes, \\\n",
        "\t\t\t\t\t\t\topt_lr_loss, opt_l2_loss, Num_EPOCHS, Dropout_Rate)\n",
        "print (\"Optimal L2: \", opt_l2_loss, \"Optimal LR: \", opt_lr_loss)\n",
        "print(\"C-index in Test: \", c_index_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0c89ffb0",
      "metadata": {
        "id": "0c89ffb0"
      },
      "outputs": [],
      "source": [
        "#%%writefile Train_for_Interpret.py\n",
        "# from Model import Cox_PASNet\n",
        "# from SubNetwork_SparseCoding import dropout_mask, s_mask\n",
        "# from Survival_CostFunc_CIndex import R_set, neg_par_log_likelihood, c_index\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "from scipy.interpolate import interp1d\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dtype = torch.FloatTensor\n",
        "\n",
        "def InterpretCoxPASNet(x, age, ytime, yevent, \\\n",
        "\t\t\t\t\t\tIn_Nodes, Hidden_Nodes, Out_Nodes, \\\n",
        "\t\t\t\t\t\tLearning_Rate, L2, Num_Epochs, Dropout_Rate, outpath):\n",
        "\n",
        "\tnet = Cox_PASNet(In_Nodes, Hidden_Nodes, Out_Nodes)\n",
        "\t###if gpu is being used\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tnet.cuda()\n",
        "\t###\n",
        "\t###optimizer\n",
        "\topt = optim.Adam(net.parameters(), lr=Learning_Rate, weight_decay = L2)\n",
        "\n",
        "\tfor epoch in range(Num_Epochs+1):\n",
        "\t\tnet.train()\n",
        "\t\topt.zero_grad() ###reset gradients to zeros\n",
        "\t\t###Randomize dropout masks\n",
        "\t\tnet.do_m1 = dropout_mask(860, Dropout_Rate[0])\n",
        "\t\tnet.do_m2 = dropout_mask(Hidden_Nodes, Dropout_Rate[1])\n",
        "\n",
        "\t\tpred = net(x, age) ###Forward\n",
        "\t\tloss = neg_par_log_likelihood(pred, ytime, yevent) ###calculate loss\n",
        "\t\tloss.backward() ###calculate gradients\n",
        "\t\topt.step() ###update weights and biases\n",
        "\n",
        "# \t\tnet.sc1.weight.data = net.sc1.weight.data.mul(net.pathway_mask) ###force the connections between gene layer and pathway layer\n",
        "\n",
        "\t\t###obtain the small sub-network's connections\n",
        "\t\tdo_m1_grad = copy.deepcopy(net.sc2.weight._grad.data)\n",
        "\t\tdo_m2_grad = copy.deepcopy(net.sc3.weight._grad.data)\n",
        "\t\tdo_m1_grad_mask = torch.where(do_m1_grad == 0, do_m1_grad, torch.ones_like(do_m1_grad))\n",
        "\t\tdo_m2_grad_mask = torch.where(do_m2_grad == 0, do_m2_grad, torch.ones_like(do_m2_grad))\n",
        "\t\t###copy the weights\n",
        "\t\tnet_sc2_weight = copy.deepcopy(net.sc2.weight.data)\n",
        "\t\tnet_sc3_weight = copy.deepcopy(net.sc3.weight.data)\n",
        "\n",
        "\t\t###serializing net\n",
        "\t\tnet_state_dict = net.state_dict()\n",
        "\n",
        "\t\t###Sparse Coding\n",
        "\t\t###make a copy for net, and then optimize sparsity level via copied net\n",
        "\t\tcopy_net = copy.deepcopy(net)\n",
        "\t\tcopy_state_dict = copy_net.state_dict()\n",
        "\t\tfor name, param in copy_state_dict.items():\n",
        "\t\t\t###omit the param if it is not a weight matrix\n",
        "\t\t\tif not \"weight\" in name:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t###omit gene layer\n",
        "\t\t\tif \"sc1\" in name:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t###stop sparse coding\n",
        "\t\t\tif \"sc4\" in name:\n",
        "\t\t\t\tbreak\n",
        "\t\t\t###sparse coding between the current two consecutive layers is in the trained small sub-network\n",
        "\t\t\tif \"sc2\" in name:\n",
        "\t\t\t\tactive_param = net_sc2_weight.mul(do_m1_grad_mask)\n",
        "\t\t\tif \"sc3\" in name:\n",
        "\t\t\t\tactive_param = net_sc3_weight.mul(do_m2_grad_mask)\n",
        "\t\t\tnonzero_param_1d = active_param[active_param != 0]\n",
        "\t\t\tif nonzero_param_1d.size(0) == 0: ###stop sparse coding between the current two consecutive layers if there are no valid weights\n",
        "\t\t\t\tbreak\n",
        "\t\t\tcopy_param_1d = copy.deepcopy(nonzero_param_1d)\n",
        "\t\t\t###set up potential sparsity level in [0, 100)\n",
        "\t\t\tS_set =  torch.arange(100, -1, -1)[1:]\n",
        "\t\t\tcopy_param = copy.deepcopy(active_param)\n",
        "\t\t\tS_loss = []\n",
        "\t\t\tfor S in S_set:\n",
        "\t\t\t\tparam_mask = s_mask(sparse_level = S.item(), param_matrix = copy_param, nonzero_param_1D = copy_param_1d, dtype = dtype)\n",
        "\t\t\t\ttransformed_param = copy_param.mul(param_mask)\n",
        "\t\t\t\tcopy_state_dict[name].copy_(transformed_param)\n",
        "\t\t\t\tcopy_net.train()\n",
        "\t\t\t\ty_tmp = copy_net(x, age)\n",
        "\t\t\t\tloss_tmp = neg_par_log_likelihood(y_tmp, ytime, yevent)\n",
        "\t\t\t\tS_loss.append(loss_tmp)\n",
        "\t\t\tprint(type(S_loss))\n",
        "\t\t\tprint(type(S_set))\n",
        "\t\t\tS_loss = torch.tensor(S_loss)\n",
        "\t\t\tS_loss = S_loss.detach().numpy()\n",
        "\t\t\tS_set = S_set.detach().numpy()\n",
        "\t\t\tprint(type(S_loss))\n",
        "\t\t\tprint(type(S_set))\n",
        "\t\t\t###apply cubic interpolation\n",
        "\t\t\tinterp_S_loss = interp1d(S_set, S_loss, kind='cubic')\n",
        "\t\t\tinterp_S_set = torch.linspace(min(S_set), max(S_set), steps=100)\n",
        "\t\t\tinterp_loss = interp_S_loss(interp_S_set)\n",
        "\t\t\toptimal_S = interp_S_set[np.argmin(interp_loss)]\n",
        "\t\t\toptimal_param_mask = s_mask(sparse_level = optimal_S.item(), param_matrix = copy_param, nonzero_param_1D = copy_param_1d, dtype = dtype)\n",
        "\t\t\tif \"sc2\" in name:\n",
        "\t\t\t\tfinal_optimal_param_mask = torch.where(do_m1_grad_mask == 0, torch.ones_like(do_m1_grad_mask), optimal_param_mask)\n",
        "\t\t\t\toptimal_transformed_param = net_sc2_weight.mul(final_optimal_param_mask)\n",
        "\t\t\tif \"sc3\" in name:\n",
        "\t\t\t\tfinal_optimal_param_mask = torch.where(do_m2_grad_mask == 0, torch.ones_like(do_m2_grad_mask), optimal_param_mask)\n",
        "\t\t\t\toptimal_transformed_param = net_sc3_weight.mul(final_optimal_param_mask)\n",
        "\t\t\t###update weights in copied net\n",
        "\t\t\tcopy_state_dict[name].copy_(optimal_transformed_param)\n",
        "\t\t\t###update weights in net\n",
        "\t\t\tnet_state_dict[name].copy_(optimal_transformed_param)\n",
        "\n",
        "\t###save the trained model\n",
        "\ttorch.save(net.state_dict(), outpath)\n",
        "\n",
        "\treturn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296da90f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "296da90f",
        "outputId": "58a43967-85b7-42b4-b94f-39a6ad0337ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#%%writefile Run_for_Interpret.py\n",
        "# from DataLoader import load_data, load_pathway\n",
        "# from Train_for_Interpret import InterpretCoxPASNet\n",
        "# from Model import Cox_PASNet\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "''' Net Settings'''\n",
        "In_Nodes = 270 ###number of genes\n",
        "Pathway_Nodes = 860 ###number of pathways\n",
        "Hidden_Nodes = 100 ###number of hidden nodes\n",
        "Out_Nodes = 30 ###number of hidden nodes in the last hidden layer\n",
        "''' Initialize '''\n",
        "Initial_Learning_Rate = 0.00075\n",
        "L2_Lambda = 0.01\n",
        "Num_EPOCHS = 900\n",
        "###sub-network setup\n",
        "Dropout_Rate = [0.7, 0.5]\n",
        "\n",
        "''' load data and pathway '''\n",
        "# pathway_mask = load_pathway(\"pathway_mask_tcga_ov.csv\", dtype)\n",
        "x, ytime, yevent, age = load_data(\"/content/entire_data_tcga_Brca.csv\", dtype)\n",
        "\n",
        "outpath = \"InterpretCoxPASNet_lin_pred_brca_nopath.pt\"\n",
        "'''train Cox-PASNet for model interpretation'''\n",
        "InterpretCoxPASNet(x, age, ytime, yevent, \\\n",
        "                   In_Nodes, Hidden_Nodes, Out_Nodes, \\\n",
        "\t\t\t\t\tInitial_Learning_Rate, L2_Lambda, Num_EPOCHS, Dropout_Rate, outpath)\n",
        "\n",
        "'''load trained Cox-PASNet'''\n",
        "net = Cox_PASNet(In_Nodes, Hidden_Nodes, Out_Nodes)\n",
        "net.load_state_dict(torch.load(outpath))\n",
        "###if gpu is being used\n",
        "if torch.cuda.is_available():\n",
        "\tnet.cuda()\n",
        "###\n",
        "'''save weights and node values into files individually'''\n",
        "w_sc1 = net.sc1.weight.data.cpu().detach().numpy()\n",
        "w_sc2 = net.sc2.weight.data.cpu().detach().numpy()\n",
        "w_sc3 = net.sc3.weight.data.cpu().detach().numpy()\n",
        "w_sc4 = net.sc4.weight.data.cpu().detach().numpy()\n",
        "np.savetxt(\"w_sc1_lin_pred_lung_nopath_150.csv\", w_sc1, delimiter = \",\")\n",
        "np.savetxt(\"w_sc2_lin_pred_lung_nopath_150.csv\", w_sc2, delimiter = \",\")\n",
        "np.savetxt(\"w_sc3_lin_pred_lung_nopath_150.csv\", w_sc3, delimiter = \",\")\n",
        "np.savetxt(\"w_sc4_lin_pred_lung_nopath_150.csv\", w_sc4, delimiter = \",\")\n",
        "\n",
        "pathway_node = net.tanh(net.sc1(x))\n",
        "hidden_node = net.tanh(net.sc2(pathway_node))\n",
        "hidden_2_node = net.tanh(net.sc3(hidden_node))\n",
        "x_cat = torch.cat((hidden_2_node, age), 1)\n",
        "lin_pred = net.sc4(x_cat)\n",
        "np.savetxt(\"pathway_lin_pred_lung_nopath_150.csv\", pathway_node.cpu().detach().numpy(), delimiter = \",\")\n",
        "np.savetxt(\"hidden_node_lin_pred_lung_nopath_150.csv\", hidden_node.cpu().detach().numpy(), delimiter = \",\")\n",
        "np.savetxt(\"hidden_2_lin_pred_lung_nopath_150.csv\", x_cat.cpu().detach().numpy(), delimiter = \",\")\n",
        "np.savetxt(\"lin_pred_lung_nopath_150.csv\", lin_pred.cpu().detach().numpy(), delimiter = \",\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8390aa53",
      "metadata": {
        "id": "8390aa53"
      },
      "outputs": [],
      "source": [
        "np.savetxt(\"lin_pred_lung_nopath_150_.csv\", lin_pred.cpu().detach().numpy(), delimiter = \",\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dPdfcHEuq94"
      },
      "id": "3dPdfcHEuq94",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}